{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aff66be-d10b-4541-a602-45e13e630d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:35:39.058702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 12:35:39.817043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-26 12:35:39.817118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-26 12:35:39.817126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] 2.11.1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#importing tensorflow, check gpu\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'), tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8906de8a-a4d6-4067-b4ea-92c49c02641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small images in h5: 32362\n"
     ]
    }
   ],
   "source": [
    "path_to_h5 = './DATA/h5_files/LC08_L2SP_02_T1_256.h5'\n",
    "with h5py.File(path_to_h5, 'r') as f:\n",
    "    LENGTH_OF_EPOCH = len(f['all/data_norm'])\n",
    "    print('Number of small images in h5:', LENGTH_OF_EPOCH)\n",
    "\n",
    "#Global variables, do not change\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNELS = 7\n",
    "CLASSES = 10\n",
    "MAX_SHIFT = 1 # максимальное смещение по вертикали и горизонтали в функции потерь\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8caf670a-82d5-4e60-b44e-3ef0c80bf7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing from local scripts\n",
    "from TrainingNN.DataLoad import BatchLoader, make_train_dataset\n",
    "from TrainingNN.BuildNN import build_resnet\n",
    "from TrainingNN.Transform import *\n",
    "from TrainingNN.Loss import conv_loss\n",
    "from TrainingNN.Visualize import VisualClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b88fe65-4a48-487f-bd0c-2e7094e7974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Задаём фильтры и размеры ядер на этапе создания модели\n",
    "###Список 'filters' - кол-во фильтров, по порядку следования слоёв 'encoder'\n",
    "###Список 'conv_kernels' - размер ядер свёрток в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "###Список 'strides' - размер 'strides' в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "def make_model(filters = [16,32,16], conv_kernel = [3,3,3]):#, strides = [2,2,2,2]):\n",
    "    \n",
    "    #Создаём основу модели\n",
    "    inp = tf.keras.layers.Input(shape=(None, None, CHANNELS))\n",
    "    \n",
    "    #classifier = simple_classifier()\n",
    "    classifier = build_resnet(filters, conv_kernel, CHANNELS, CLASSES)\n",
    "    #classifier = build_unet(filters, conv_kernel, strides)\n",
    "\n",
    "    outp = classifier(inp)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    #По гиперпараметрам генерируем имя модели\n",
    "    s = 'f'\n",
    "    for i in filters:\n",
    "        s +='.'+str(i)\n",
    "    s+='_k'\n",
    "    for i in conv_kernel:\n",
    "        s +='.'+str(i)\n",
    "    s+='_s'\n",
    "    #for i in strides:\n",
    "    #    s +='.'+str(i)\n",
    "    \n",
    "    model_name = str(classifier.name)+'_'+s+'_CLASSES.'+str(CLASSES)+'_BS.'+str(BATCH_SIZE)\n",
    "    \n",
    "    #Алгоритм подсчёта лосса\n",
    "    params, inverse_params = RandomAffineTransformParams()(inp, WIDTH)\n",
    "    transformed_inp = ImageProjectiveTransformLayer()(inp, params, WIDTH, HEIGHT)\n",
    "    transformed_outp = classifier(transformed_inp)\n",
    "    inv_transformed_outp = ImageProjectiveTransformLayer()(transformed_outp, inverse_params)\n",
    "    model.add_loss(conv_loss(outp, inv_transformed_outp, WIDTH, HEIGHT, BATCH_SIZE))\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a7168-9452-4831-8862-969276b2ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:35:41.536549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 12:35:42.064752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10572 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16\n",
      "directory for the model already exists\n",
      "directory for tb logs is created\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:35:46.441597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-09-26 12:35:47.121169: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-26 12:35:47.221945: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x1c295b00\n",
      "2023-09-26 12:35:53.742239: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1f2e3ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-26 12:35:53.742284: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-09-26 12:35:53.747611: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-26 12:35:53.830288: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-26 12:35:53.893368: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/2022 [..............................] - ETA: 6:43 - loss: -0.0149WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0255s vs `on_train_batch_end` time: 0.3837s). Check your callbacks.\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -0.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 427s 203ms/step - loss: -0.8854\n",
      "Epoch 2/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.3377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 411s 203ms/step - loss: -1.3377\n",
      "Epoch 3/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.4504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.4504\n",
      "Epoch 4/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.5384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 411s 203ms/step - loss: -1.5384\n",
      "Epoch 5/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.6225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.6225\n",
      "Epoch 6/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 204ms/step - loss: -1.6572\n",
      "Epoch 7/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.6842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 413s 204ms/step - loss: -1.6842\n",
      "Epoch 8/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 413s 204ms/step - loss: -1.7336\n",
      "Epoch 9/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 204ms/step - loss: -1.7593\n",
      "Epoch 10/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.7741\n",
      "Epoch 11/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.7848\n",
      "Epoch 12/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.7932\n",
      "Epoch 13/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 413s 204ms/step - loss: -1.8003\n",
      "Epoch 14/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.8063\n",
      "Epoch 15/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 413s 204ms/step - loss: -1.8115\n",
      "Epoch 16/100\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.16.32.16_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 412s 203ms/step - loss: -1.8162\n",
      "Epoch 17/100\n",
      " 137/2022 [=>............................] - ETA: 6:11 - loss: -1.8513"
     ]
    }
   ],
   "source": [
    "model, model_name = make_model()\n",
    "print(model_name)\n",
    "\n",
    "# making dir for model if necessary\n",
    "try:\n",
    "    os.makedirs('../models/'+model_name)\n",
    "    print('directory for the model is created')\n",
    "except:\n",
    "    print('directory for the model already exists')\n",
    "#make a dir for tensorboard logs\n",
    "logdir = \"./models/logs_tb/\"+model_name+\"/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(logdir)\n",
    "print('directory for tb logs is created')\n",
    "    \n",
    "#Make callbacks: draw a pic after every epoch, early stopping, model checkpoint, logs to tensorboard\n",
    "class DrawTestPic(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,J):\n",
    "        self.J = J\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch%200 == 0:\n",
    "            self.J+=1\n",
    "            V = VisualClass(path_to_h5)\n",
    "            no = 72\n",
    "            img_norm, GEO = V.get_norm_image(no,no+1)\n",
    "            predicted = model.predict(img_norm, verbose = False)\n",
    "            predicted_classes = predicted.argmax(axis = -1)\n",
    "            try:\n",
    "                os.makedirs(\"./models/\"+model_name+\"/figures/fig\"+str(no))\n",
    "            except:\n",
    "                pass\n",
    "            f = V.draw_layers(no, predicted_classes)\n",
    "            f.write_html(\"./models/\"+model_name+\"/figures/fig\"+str(no)+\"/\"+str(self.J)+\".html\")\n",
    "\n",
    "callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, min_delta=5e-4),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath='../models/' + model_name + '/best',\n",
    "                                                   monitor = 'loss',\n",
    "                                                   save_freq='epoch'), \n",
    "                tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "                DrawTestPic(J = 0)\n",
    "            ]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "train_dataset = make_train_dataset(path_to_h5, BATCH_SIZE, WIDTH, HEIGHT, CHANNELS)\n",
    "history = model.fit(train_dataset, epochs = 100,\n",
    "                    steps_per_epoch = LENGTH_OF_EPOCH // BATCH_SIZE,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = 1)\n",
    "model.save('./models/'+ model_name + '/last')\n",
    "print('Model' + model_name + 'has been trained.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
