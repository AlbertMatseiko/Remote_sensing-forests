{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aff66be-d10b-4541-a602-45e13e630d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] 2.11.1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#importing tensorflow, check gpu\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'), tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8906de8a-a4d6-4067-b4ea-92c49c02641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small images in h5: 32362\n"
     ]
    }
   ],
   "source": [
    "path_to_h5 = './DATA/h5_files/LC08_L2SP_02_T1_256.h5'\n",
    "with h5py.File(path_to_h5, 'r') as f:\n",
    "    LENGTH_OF_EPOCH = len(f['all/data_norm'])\n",
    "    print('Number of small images in h5:', LENGTH_OF_EPOCH)\n",
    "\n",
    "#Global variables, do not change\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNELS = 7\n",
    "CLASSES = 10\n",
    "MAX_SHIFT = 1 # максимальное смещение по вертикали и горизонтали в функции потерь\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8caf670a-82d5-4e60-b44e-3ef0c80bf7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing from local scripts\n",
    "from TrainingNN.DataLoad import BatchLoader, make_train_dataset\n",
    "from TrainingNN.BuildNN import build_resnet\n",
    "from TrainingNN.Transform import *\n",
    "from TrainingNN.Loss import conv_loss\n",
    "from TrainingNN.Visualize import VisualClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b88fe65-4a48-487f-bd0c-2e7094e7974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Задаём фильтры и размеры ядер на этапе создания модели\n",
    "###Список 'filters' - кол-во фильтров, по порядку следования слоёв 'encoder'\n",
    "###Список 'conv_kernels' - размер ядер свёрток в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "###Список 'strides' - размер 'strides' в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "def make_model(filters = [32,32,32], conv_kernel = [3,3,3]):#, strides = [2,2,2,2]):\n",
    "    \n",
    "    #Создаём основу модели\n",
    "    inp = tf.keras.layers.Input(shape=(None, None, CHANNELS))\n",
    "    \n",
    "    #classifier = simple_classifier()\n",
    "    classifier = build_resnet(filters, conv_kernel, CHANNELS, CLASSES)\n",
    "    #classifier = build_unet(filters, conv_kernel, strides)\n",
    "\n",
    "    outp = classifier(inp)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    #По гиперпараметрам генерируем имя модели\n",
    "    s = 'f'\n",
    "    for i in filters:\n",
    "        s +='.'+str(i)\n",
    "    s+='_k'\n",
    "    for i in conv_kernel:\n",
    "        s +='.'+str(i)\n",
    "    s+='_s'\n",
    "    #for i in strides:\n",
    "    #    s +='.'+str(i)\n",
    "    \n",
    "    model_name = str(classifier.name)+'_'+s+'_CLASSES.'+str(CLASSES)+'_BS.'+str(BATCH_SIZE)\n",
    "    \n",
    "    #Алгоритм подсчёта лосса\n",
    "    params, inverse_params = RandomAffineTransformParams()(inp, WIDTH)\n",
    "    transformed_inp = ImageProjectiveTransformLayer()(inp, params, WIDTH, HEIGHT)\n",
    "    transformed_outp = classifier(transformed_inp)\n",
    "    inv_transformed_outp = ImageProjectiveTransformLayer()(transformed_outp, inverse_params)\n",
    "    model.add_loss(conv_loss(outp, inv_transformed_outp, WIDTH, HEIGHT, BATCH_SIZE))\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "893a7168-9452-4831-8862-969276b2ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16\n",
      "directory for the model is created\n",
      "directory for tb logs is created\n",
      "Epoch 1/15\n",
      "   6/2022 [..............................] - ETA: 7:42 - loss: -0.0150WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.1830s). Check your callbacks.\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -0.9678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 961s 470ms/step - loss: -0.9678\n",
      "Epoch 2/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.4093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 232ms/step - loss: -1.4093\n",
      "Epoch 3/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.5152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 469s 232ms/step - loss: -1.5152\n",
      "Epoch 4/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.5680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 469s 232ms/step - loss: -1.5680\n",
      "Epoch 5/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.6740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 232ms/step - loss: -1.6740\n",
      "Epoch 6/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 233ms/step - loss: -1.7512\n",
      "Epoch 7/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 471s 233ms/step - loss: -1.7774\n",
      "Epoch 8/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.7943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 469s 232ms/step - loss: -1.7943\n",
      "Epoch 9/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 233ms/step - loss: -1.8068\n",
      "Epoch 10/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 469s 232ms/step - loss: -1.8168\n",
      "Epoch 11/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 232ms/step - loss: -1.8248\n",
      "Epoch 12/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 471s 233ms/step - loss: -1.8317\n",
      "Epoch 13/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 232ms/step - loss: -1.8378\n",
      "Epoch 14/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 469s 232ms/step - loss: -1.8429\n",
      "Epoch 15/15\n",
      "2022/2022 [==============================] - ETA: 0s - loss: -1.8475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/2022 [==============================] - 470s 233ms/step - loss: -1.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/last/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16/last/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResNet_f.32.32.32_k.3.3.3_s_CLASSES.10_BS.16has been trained.\n"
     ]
    }
   ],
   "source": [
    "model, model_name = make_model()\n",
    "print(model_name)\n",
    "\n",
    "# making dir for model if necessary\n",
    "try:\n",
    "    os.makedirs('../models/'+model_name)\n",
    "    print('directory for the model is created')\n",
    "except:\n",
    "    print('directory for the model already exists')\n",
    "#make a dir for tensorboard logs\n",
    "logdir = \"./models/logs_tb/\"+model_name+\"/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(logdir)\n",
    "print('directory for tb logs is created')\n",
    "    \n",
    "\n",
    "#Make callbacks: draw a pic after every epoch, early stopping, model checkpoint, logs to tensorboard\n",
    "class DrawTestPic(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        V = VisualClass(path_to_h5)\n",
    "        img_norm, GEO = V.get_norm_image(0,10)\n",
    "        predicted = model.predict(img_norm, verbose = False)\n",
    "        predicted_classes = predicted.argmax(axis = -1)\n",
    "        no = 6\n",
    "        try:\n",
    "            os.makedirs(\"./models/\"+model_name+\"/figures/fig\"+str(no))\n",
    "        except:\n",
    "            pass\n",
    "        f = V.draw_layers(no, predicted_classes)\n",
    "        f.write_html(\"./models/\"+model_name+\"/figures/fig\"+str(no)+\"/\"+str(epoch)+\".html\")\n",
    "\n",
    "callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, min_delta=5e-4),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath='../models/' + model_name + '/best',\n",
    "                                                   monitor = 'loss',\n",
    "                                                   save_freq='epoch'), \n",
    "                tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "                DrawTestPic()\n",
    "            ]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "train_dataset = make_train_dataset(path_to_h5, BATCH_SIZE, WIDTH, HEIGHT, CHANNELS)\n",
    "history = model.fit(train_dataset, epochs = 15,\n",
    "                    steps_per_epoch = LENGTH_OF_EPOCH // BATCH_SIZE,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = 1)\n",
    "model.save('./models/'+ model_name + '/last')\n",
    "print('Model' + model_name + 'has been trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75885767-cdd9-4299-baff-30c69d21f4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
