{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#importing tensorflow, check gpu\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'), tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#importing from local scripts\n",
    "from DataLoad import BatchLoader, make_train_dataset\n",
    "from BuildNN import build_resnet\n",
    "from Transform import *\n",
    "from Loss import conv_loss\n",
    "from Visualize import Visual\n",
    "\n",
    "\n",
    "path_to_h5 = '../data/LC08_L2SP_02_T1_cropped.h5'\n",
    "with h5py.File(path_to_h5, 'r') as f:\n",
    "    LENGTH_OF_EPOCH = len(f['all/data_norm'])\n",
    "    print('Number of small images in h5:', LENGTH_OF_EPOCH)\n",
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "CHANNELS = 7\n",
    "CLASSES = 10\n",
    "MAX_SHIFT = 1 # максимальное смещение по вертикали и горизонтали в функции потерь\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "###Задаём фильтры и размеры ядер на этапе создания модели\n",
    "###Список 'filters' - кол-во фильтров, по порядку следования слоёв 'encoder'\n",
    "###Список 'conv_kernels' - размер ядер свёрток в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "###Список 'strides' - размер 'strides' в 'encoder' и 'decoder', по порядку следования слоёв 'encoder'\n",
    "def make_model(filters = [64,64,64], conv_kernel = [3,3,3]):#, strides = [2,2,2,2]):\n",
    "    \n",
    "    #Создаём основу модели\n",
    "    inp = tf.keras.layers.Input(shape=(None, None, CHANNELS))\n",
    "    \n",
    "    #classifier = simple_classifier()\n",
    "    classifier = build_resnet(filters, conv_kernel, CHANNELS, CLASSES)\n",
    "    #classifier = build_unet(filters, conv_kernel, strides)\n",
    "\n",
    "    outp = classifier(inp)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    #По гиперпараметрам генерируем имя модели\n",
    "    s = 'f'\n",
    "    for i in filters:\n",
    "        s +='.'+str(i)\n",
    "    s+='_k'\n",
    "    for i in conv_kernel:\n",
    "        s +='.'+str(i)\n",
    "    s+='_s'\n",
    "    #for i in strides:\n",
    "    #    s +='.'+str(i)\n",
    "    \n",
    "    model_name = str(classifier.name)+'_'+s+'_CLASSES.'+str(CLASSES)+'_BS.'+str(BATCH_SIZE)\n",
    "    \n",
    "    #Алгоритм подсчёта лосса\n",
    "    params, inverse_params = RandomAffineTransformParams()(inp, WIDTH)\n",
    "    transformed_inp = ImageProjectiveTransformLayer()(inp, params, WIDTH, HEIGHT)\n",
    "    transformed_outp = classifier(transformed_inp)\n",
    "    inv_transformed_outp = ImageProjectiveTransformLayer()(transformed_outp, inverse_params)\n",
    "    model.add_loss(conv_loss(outp, inv_transformed_outp, WIDTH, HEIGHT, BATCH_SIZE))\n",
    "    return model, model_name\n",
    "\n",
    "model, model_name = make_model()\n",
    "print(model_name)\n",
    "\n",
    "# making dir for model if necessary\n",
    "try:\n",
    "    os.makedirs('../models/'+model_name)\n",
    "    print('directory for the model is created')\n",
    "except:\n",
    "    print('directory for the model already exists')\n",
    "#make a dir for tensorboard logs\n",
    "logdir = \"../models/logs_tb/\"+model_name+\"/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(logdir)\n",
    "print('directory for tb logs is created')\n",
    "    \n",
    "\n",
    "#Make callbacks: draw a pic after every epoch, early stopping, model checkpoint, logs to tensorboard\n",
    "class DrawTestPic(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        V = Visual(path_to_h5)\n",
    "        img_norm, GEO = V.get_norm_image(0,10)\n",
    "        predicted = model.predict(img_norm, verbose = False)\n",
    "        predicted_classes = predicted.argmax(axis = -1)\n",
    "        no = 6\n",
    "        try:\n",
    "            os.makedirs(\"../models/\"+model_name+\"/figures/fig\"+str(no))\n",
    "        except:\n",
    "            pass\n",
    "        f = V.draw_layers(no, predicted_classes)\n",
    "        f.write_html(\"../models/\"+model_name+\"/figures/fig\"+str(no)+\"/\"+str(epoch)+\".html\")\n",
    "\n",
    "callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, min_delta=5e-4),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath='../models/' + model_name + '/best',\n",
    "                                                   monitor = 'loss',\n",
    "                                                   save_freq='epoch'), \n",
    "                tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "                DrawTestPic()\n",
    "            ]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4))\n",
    "\n",
    "train_dataset = make_train_dataset(path_to_h5, BATCH_SIZE, WIDTH, HEIGHT, CHANNELS)\n",
    "history = model.fit(train_dataset, epochs = 100, #по факту: 10 проходов по большому файлу\n",
    "                    steps_per_epoch = LENGTH_OF_EPOCH // BATCH_SIZE//10, #берём для тренировки большой файл\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = 1)\n",
    "model.save('../models/'+ model_name + '/last')\n",
    "print('Model' + model_name + 'has been trained.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
